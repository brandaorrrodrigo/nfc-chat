/**
 * An√°lise de V√≠deo com Vision Models (llama3.2-vision / llava)
 * Extrai frames e analisa com LLM multimodal
 * Suporta v√≠deos locais e do Supabase Storage
 */

import axios from 'axios';
import { exec } from 'child_process';
import { promisify } from 'util';
import * as fs from 'fs/promises';
import * as path from 'path';
import { createClient } from '@supabase/supabase-js';

const execAsync = promisify(exec);

const OLLAMA_URL = process.env.OLLAMA_URL || 'http://localhost:11434';
const VISION_MODEL = process.env.VISION_MODEL || 'llama3.2-vision:latest';
const VISION_MODEL_FALLBACK = 'llava:latest'; // Fallback se llama3.2-vision n√£o dispon√≠vel

// Detectar sistema operacional
const isWindows = process.platform === 'win32';

// Caminhos absolutos para ffmpeg/ffprobe no Windows (evita problema com /bin/sh no PATH)
const FFMPEG_BIN = isWindows
  ? (process.env.FFMPEG_PATH || 'C:\\ProgramData\\chocolatey\\bin\\ffmpeg.exe')
  : 'ffmpeg';
const FFPROBE_BIN = isWindows
  ? (process.env.FFPROBE_PATH || 'C:\\ProgramData\\chocolatey\\bin\\ffprobe.exe')
  : 'ffprobe';
const EXEC_OPTIONS = isWindows ? { shell: 'cmd.exe' } : {};

/**
 * Verifica se ffmpeg est√° instalado
 */
export async function checkFfmpegAvailable(): Promise<boolean> {
  try {
    await execAsync(`"${FFMPEG_BIN}" -version`, EXEC_OPTIONS);
    return true;
  } catch {
    console.warn('‚ö†Ô∏è ffmpeg n√£o encontrado. Instale com: choco install ffmpeg (Windows) ou brew install ffmpeg (Mac)');
    return false;
  }
}

// Supabase client para download de v√≠deos
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL || '';
const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY || process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY || '';
const supabase = supabaseUrl && supabaseKey ? createClient(supabaseUrl, supabaseKey) : null;

export interface VideoAnalysisOptions {
  videoPath?: string;
  videoUrl?: string; // URL do Supabase Storage ou URL p√∫blica
  exerciseType?: string;
  focusAreas?: string[];
  framesCount?: number;
}

/**
 * Baixa v√≠deo do Supabase Storage para arquivo tempor√°rio
 */
export async function downloadVideoFromSupabase(
  videoPath: string,
  outputDir: string
): Promise<string> {
  if (!supabase) {
    throw new Error('Supabase n√£o configurado');
  }

  const bucketName = 'nfv-videos';
  const localPath = path.join(outputDir, `video_${Date.now()}.mp4`);

  console.log(`‚¨áÔ∏è Downloading video from Supabase: ${videoPath}`);

  const { data, error } = await supabase.storage
    .from(bucketName)
    .download(videoPath);

  if (error) {
    throw new Error(`Erro ao baixar v√≠deo: ${error.message}`);
  }

  // Converter Blob para Buffer e salvar
  const arrayBuffer = await data.arrayBuffer();
  const buffer = Buffer.from(arrayBuffer);
  await fs.writeFile(localPath, buffer);

  console.log(`‚úÖ Video downloaded to: ${localPath}`);
  return localPath;
}

/**
 * Baixa v√≠deo de URL p√∫blica
 */
export async function downloadVideoFromUrl(
  videoUrl: string,
  outputDir: string
): Promise<string> {
  const localPath = path.join(outputDir, `video_${Date.now()}.mp4`);

  console.log(`‚¨áÔ∏è Downloading video from URL: ${videoUrl}`);

  const response = await axios.get(videoUrl, {
    responseType: 'arraybuffer',
    timeout: 120000, // 2 min timeout
  });

  await fs.writeFile(localPath, Buffer.from(response.data));

  console.log(`‚úÖ Video downloaded to: ${localPath}`);
  return localPath;
}

export interface FrameAnalysis {
  frameNumber: number;
  timestamp: number;
  analysis: string;
  issues: string[];
  score: number;
}

export interface VideoAnalysisResult {
  exerciseType: string;
  overallScore: number;
  frames: FrameAnalysis[];
  summary: string;
  recommendations: string[];
  technicalIssues: string[];
}

/**
 * Extrai um √∫nico frame (fallback quando ffmpeg tem limita√ß√µes)
 */
export async function extractSingleFrame(
  videoPath: string,
  outputDir: string
): Promise<string | null> {
  try {
    const framePath = path.join(outputDir, 'frame_001.jpg');

    // Tentar extrair frame no segundo 1
    await execAsync(
      `"${FFMPEG_BIN}" -ss 1 -i "${videoPath}" -vframes 1 -q:v 2 "${framePath}" -y`,
      EXEC_OPTIONS
    );

    // Verificar se arquivo foi criado
    await fs.access(framePath);
    return framePath;
  } catch (error) {
    console.error('Erro ao extrair frame √∫nico:', error);
    return null;
  }
}

/**
 * Extrai frames de um v√≠deo usando ffmpeg
 */
export async function extractFrames(
  videoPath: string,
  outputDir: string,
  framesCount: number = 10
): Promise<string[]> {
  console.log(`üé¨ Extracting ${framesCount} frames from video...`);

  try {
    // Criar diret√≥rio de output
    await fs.mkdir(outputDir, { recursive: true });

    // Obter dura√ß√£o do v√≠deo
    const { stdout: durationOutput } = await execAsync(
      `"${FFPROBE_BIN}" -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 "${videoPath}"`,
      EXEC_OPTIONS
    );

    const duration = parseFloat(durationOutput.trim());
    console.log(`  Video duration: ${duration.toFixed(2)}s`);

    // Calcular intervalo entre frames ‚Äî divide o v√≠deo em N+1 segmentos
    // Garante que nenhum frame busca exatamente o final do v√≠deo (evita EOF error)
    // Exemplo: 48 frames em 80s ‚Üí interval=1.63s ‚Üí frames distribu√≠dos de 1.63s at√© 78.43s
    const interval = duration / (framesCount + 1);

    const framePaths: string[] = [];

    // Extrair frames em momentos espec√≠ficos
    for (let i = 1; i <= framesCount; i++) {
      const timestamp = interval * i;
      const framePath = path.join(outputDir, `frame_${i.toString().padStart(3, '0')}.jpg`);

      await execAsync(
        `"${FFMPEG_BIN}" -ss ${timestamp} -i "${videoPath}" -vframes 1 -q:v 2 "${framePath}" -y`,
        EXEC_OPTIONS
      );

      framePaths.push(framePath);
    }

    console.log(`‚úÖ Extracted ${framePaths.length} frames`);
    return framePaths;
  } catch (error: any) {
    console.error('‚ùå Error extracting frames:', error.message);
    throw new Error(`Failed to extract frames: ${error.message}`);
  }
}

/**
 * Converte imagem para base64
 */
async function imageToBase64(imagePath: string): Promise<string> {
  const buffer = await fs.readFile(imagePath);
  return buffer.toString('base64');
}

/**
 * Analisa um frame com Vision Model
 */
export async function analyzeFrame(
  imagePath: string,
  prompt: string,
  frameNumber: number,
  modelOverride?: string
): Promise<FrameAnalysis> {
  console.log(`üîç Analyzing frame ${frameNumber}...`);

  try {
    // Converter imagem para base64
    const imageBase64 = await imageToBase64(imagePath);

    // Determinar qual modelo usar
    const modelToUse = modelOverride || await getBestVisionModel() || VISION_MODEL;
    console.log(`   Using model: ${modelToUse}`);

    // Chamar Ollama Vision API
    const response = await axios.post(
      `${OLLAMA_URL}/api/generate`,
      {
        model: modelToUse,
        prompt,
        images: [imageBase64],
        stream: false,
        options: {
          temperature: 0.3,
          num_predict: 300,
        },
      },
      {
        timeout: 120000, // 2 min timeout (modelos de vis√£o s√£o mais lentos)
      }
    );

    const analysis = response.data.response || '';

    // Extrair issues mencionados
    const issues: string[] = [];
    const lowerAnalysis = analysis.toLowerCase();

    const issueKeywords = [
      'problema',
      'erro',
      'incorreto',
      'compensa√ß√£o',
      'valgo',
      'arredondamento',
      'inclina√ß√£o excessiva',
      'falta de',
    ];

    issueKeywords.forEach((keyword) => {
      if (lowerAnalysis.includes(keyword)) {
        // Extrair frase contendo o keyword
        const sentences = analysis.split(/[.!?]/);
        const issueSentence = sentences.find((s) =>
          s.toLowerCase().includes(keyword)
        );
        if (issueSentence) {
          issues.push(issueSentence.trim());
        }
      }
    });

    // Calcular score b√°sico (0-10)
    const score = calculateFrameScore(analysis, issues.length);

    return {
      frameNumber,
      timestamp: 0, // Ser√° calculado depois
      analysis,
      issues,
      score,
    };
  } catch (error: any) {
    console.error(`‚ùå Error analyzing frame ${frameNumber}:`, error.message);

    return {
      frameNumber,
      timestamp: 0,
      analysis: 'Erro ao analisar frame',
      issues: [],
      score: 5,
    };
  }
}

/**
 * Calcula score de um frame (0-10)
 */
function calculateFrameScore(analysis: string, issuesCount: number): number {
  let score = 10;

  // Penalizar por issues
  score -= issuesCount * 1.5;

  // B√¥nus se mencionar execu√ß√£o correta
  if (analysis.toLowerCase().includes('correto') || analysis.toLowerCase().includes('boa')) {
    score += 1;
  }

  // Penalizar se mencionar "grave" ou "severo"
  if (analysis.toLowerCase().includes('grave') || analysis.toLowerCase().includes('severo')) {
    score -= 2;
  }

  return Math.max(0, Math.min(10, score));
}

/**
 * Analisa v√≠deo completo de exerc√≠cio
 * Suporta videoPath local ou videoUrl do Supabase/URL p√∫blica
 */
export async function analyzeExerciseVideo(
  options: VideoAnalysisOptions
): Promise<VideoAnalysisResult> {
  const {
    videoPath,
    videoUrl,
    exerciseType = 'exerc√≠cio',
    focusAreas = ['t√©cnica geral', 'postura', 'amplitude'],
    framesCount = 8,
  } = options;

  console.log(`üé• Starting video analysis: ${exerciseType}`);

  // 1. Criar diret√≥rio tempor√°rio para frames e downloads
  const tempDir = path.join(process.cwd(), 'temp', `analysis_${Date.now()}`);

  try {
    await fs.mkdir(tempDir, { recursive: true });

    // 2. Obter path do v√≠deo (baixar se necess√°rio)
    let localVideoPath: string | undefined;

    // Verificar se videoPath √© um arquivo local que existe
    if (videoPath) {
      try {
        await fs.access(videoPath);
        localVideoPath = videoPath;
        console.log(`üìÅ Using local video file: ${videoPath}`);
      } catch {
        // videoPath n√£o √© um arquivo local ‚Äî √© um path no Supabase Storage
        console.log(`‚òÅÔ∏è videoPath "${videoPath}" is not a local file, downloading from storage...`);
        localVideoPath = await downloadVideoFromSupabase(videoPath, tempDir);
      }
    }

    // Se n√£o conseguiu via videoPath, tentar via videoUrl
    if (!localVideoPath && videoUrl) {
      if (videoUrl.includes('supabase') || videoUrl.startsWith(supabaseUrl || '')) {
        const urlPath = videoUrl.split('/nfv-videos/')[1] || videoUrl;
        localVideoPath = await downloadVideoFromSupabase(urlPath, tempDir);
      } else {
        localVideoPath = await downloadVideoFromUrl(videoUrl, tempDir);
      }
    }

    if (!localVideoPath) {
      throw new Error('videoPath ou videoUrl √© obrigat√≥rio');
    }

    // 3. Verificar se ffmpeg est√° dispon√≠vel
    const ffmpegAvailable = await checkFfmpegAvailable();

    let framePaths: string[] = [];

    if (ffmpegAvailable) {
      // 4. Extrair frames do v√≠deo com ffmpeg
      framePaths = await extractFrames(localVideoPath, tempDir, framesCount);
    } else {
      // Fallback: Usar thumbnail se dispon√≠vel, ou analisar primeiro frame
      console.log('‚ö†Ô∏è ffmpeg n√£o dispon√≠vel. Tentando an√°lise com frame √∫nico...');

      // Tentar extrair um √∫nico frame de forma alternativa
      try {
        const singleFramePath = await extractSingleFrame(localVideoPath, tempDir);
        if (singleFramePath) {
          framePaths = [singleFramePath];
        }
      } catch (frameError) {
        console.warn('N√£o foi poss√≠vel extrair frame:', frameError);
      }

      if (framePaths.length === 0) {
        throw new Error('ffmpeg n√£o instalado. Instale com: choco install ffmpeg (Windows) ou brew install ffmpeg (Mac)');
      }
    }

    // 4. Obter melhor modelo de vis√£o dispon√≠vel
    const visionModel = await getBestVisionModel();
    if (!visionModel) {
      throw new Error('Nenhum modelo de vis√£o dispon√≠vel. Execute: ollama pull llama3.2-vision');
    }
    console.log(`ü§ñ Using vision model: ${visionModel}`);

    // 5. Preparar prompt
    const prompt = `Voc√™ √© um especialista em biomec√¢nica analisando um v√≠deo de ${exerciseType}.

Analise este frame e identifique:
- T√©cnica e execu√ß√£o
- Postura e alinhamento
- Poss√≠veis compensa√ß√µes
- Pontos de aten√ß√£o
- Aspectos positivos

√Åreas de foco: ${focusAreas.join(', ')}

Seja objetivo e t√©cnico. Mencione APENAS o que voc√™ v√™ neste frame espec√≠fico.`;

    // 6. Analisar cada frame
    const frameAnalyses: FrameAnalysis[] = [];

    for (let i = 0; i < framePaths.length; i++) {
      const analysis = await analyzeFrame(framePaths[i], prompt, i + 1, visionModel);

      // Calcular timestamp
      const videoDuration = 10; // Placeholder - seria calculado com ffprobe
      analysis.timestamp = (videoDuration / (framesCount + 1)) * (i + 1);

      frameAnalyses.push(analysis);

      // Delay para n√£o sobrecarregar
      if (i < framePaths.length - 1) {
        await new Promise((resolve) => setTimeout(resolve, 500));
      }
    }

    // 5. Calcular score geral
    const overallScore =
      frameAnalyses.reduce((sum, f) => sum + f.score, 0) / frameAnalyses.length;

    // 6. Extrair issues t√©cnicos √∫nicos
    const allIssues = frameAnalyses.flatMap((f) => f.issues);
    const technicalIssues = [...new Set(allIssues)];

    // 7. Gerar recomenda√ß√µes
    const recommendations = generateRecommendations(technicalIssues, overallScore);

    // 8. Gerar sum√°rio
    const summary = generateSummary(exerciseType, overallScore, technicalIssues.length);

    // 9. Limpar arquivos tempor√°rios
    try {
      await fs.rm(tempDir, { recursive: true });
    } catch (error) {
      console.warn('Failed to clean temp files:', error);
    }

    console.log(`‚úÖ Video analysis complete (score: ${overallScore.toFixed(1)}/10)`);

    return {
      exerciseType,
      overallScore,
      frames: frameAnalyses,
      summary,
      recommendations,
      technicalIssues,
    };
  } catch (error: any) {
    console.error('‚ùå Video analysis failed:', error.message);
    throw error;
  }
}

/**
 * Gera recomenda√ß√µes baseadas nos issues
 */
function generateRecommendations(issues: string[], score: number): string[] {
  const recommendations: string[] = [];

  if (score >= 8) {
    recommendations.push('Execu√ß√£o est√° boa! Continue focando na t√©cnica.');
  } else if (score >= 6) {
    recommendations.push('T√©cnica adequada, mas h√° pontos para melhorar.');
  } else {
    recommendations.push('Recomendado focar na corre√ß√£o t√©cnica antes de aumentar carga.');
  }

  if (issues.length > 0) {
    recommendations.push('Revise os pontos t√©cnicos identificados em cada frame.');
  }

  if (issues.some((i) => i.toLowerCase().includes('postura'))) {
    recommendations.push('Trabalhe consci√™ncia postural antes de executar o movimento.');
  }

  if (issues.some((i) => i.toLowerCase().includes('amplitude'))) {
    recommendations.push('Foque em amplitude de movimento completa e controlada.');
  }

  return recommendations;
}

/**
 * Gera sum√°rio da an√°lise
 */
function generateSummary(exerciseType: string, score: number, issuesCount: number): string {
  if (score >= 8) {
    return `An√°lise de ${exerciseType}: Execu√ß√£o t√©cnica de alta qualidade. ${issuesCount === 0 ? 'Nenhum issue detectado.' : `${issuesCount} pontos de aten√ß√£o identificados.`}`;
  } else if (score >= 6) {
    return `An√°lise de ${exerciseType}: Execu√ß√£o adequada com ${issuesCount} pontos para melhoria. Continue praticando com aten√ß√£o √† t√©cnica.`;
  } else {
    return `An√°lise de ${exerciseType}: Execu√ß√£o precisa de corre√ß√µes t√©cnicas. ${issuesCount} issues identificados que podem comprometer resultado ou causar les√£o.`;
  }
}

/**
 * Verifica se Vision Model est√° dispon√≠vel e retorna qual usar
 */
export async function checkVisionModelAvailable(): Promise<boolean> {
  try {
    const response = await axios.get(`${OLLAMA_URL}/api/tags`, { timeout: 5000 });
    const models = response.data.models || [];
    const modelNames = models.map((m: any) => m.name);

    // Verificar modelo prim√°rio ou fallback
    const hasVisionModel = modelNames.includes(VISION_MODEL) ||
                          modelNames.includes('llama3.2-vision') ||
                          modelNames.includes(VISION_MODEL_FALLBACK) ||
                          modelNames.includes('llava');

    if (hasVisionModel) {
      console.log('‚úÖ Vision model dispon√≠vel:', modelNames.filter((n: string) =>
        n.includes('vision') || n.includes('llava')
      ));
    }

    return hasVisionModel;
  } catch (error) {
    console.error('‚ùå Error checking vision model:', error);
    return false;
  }
}

/**
 * Retorna o melhor modelo de vis√£o dispon√≠vel
 */
export async function getBestVisionModel(): Promise<string | null> {
  try {
    const response = await axios.get(`${OLLAMA_URL}/api/tags`, { timeout: 5000 });
    const models = response.data.models || [];
    const modelNames = models.map((m: any) => m.name);

    // Ordem de prefer√™ncia
    const preferredModels = [
      'llama3.2-vision:latest',
      'llama3.2-vision',
      'llava:latest',
      'llava',
    ];

    for (const model of preferredModels) {
      if (modelNames.includes(model)) {
        return model;
      }
    }

    return null;
  } catch (error) {
    return null;
  }
}
