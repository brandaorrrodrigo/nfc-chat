# üß™ Instru√ß√µes de Teste - Pipeline de V√≠deo NFC/NFV

Guia passo-a-passo para testar o sistema de processamento de v√≠deo com MediaPipe.

---

## üìã Pr√©-requisitos

### 1. Instalar FFmpeg

**Windows (Chocolatey):**
```bash
choco install ffmpeg
```

**Windows (Manual):**
1. Baixar em: https://ffmpeg.org/download.html
2. Extrair para `C:\ffmpeg`
3. Adicionar ao PATH: `C:\ffmpeg\bin`
4. Reiniciar terminal

**Verificar instala√ß√£o:**
```bash
ffmpeg -version
```

### 2. Instalar Depend√™ncias Node.js

```bash
# Navegar para raiz do projeto
cd D:\NUTRIFITCOACH_MASTER\nfc-comunidades

# Instalar depend√™ncias
npm install @tensorflow/tfjs-node@^4.15.0
npm install @tensorflow-models/pose-detection@^2.1.0
npm install fluent-ffmpeg@^2.1.2
npm install canvas@^2.11.2
npm install --save-dev @types/fluent-ffmpeg@^2.1.24
```

**Nota**: Se erro no Windows ao instalar canvas:
```bash
npm install --global --production windows-build-tools
npm install canvas --build-from-source
```

### 3. Verificar Instala√ß√£o

```bash
# TensorFlow.js
node -e "require('@tensorflow/tfjs-node'); console.log('‚úÖ TensorFlow OK')"

# Canvas
node -e "require('canvas'); console.log('‚úÖ Canvas OK')"

# FFmpeg bindings
node -e "require('fluent-ffmpeg'); console.log('‚úÖ FFmpeg OK')"
```

---

## üé• Preparar V√≠deos de Teste

### Op√ß√£o 1: Usar V√≠deos de Exemplo

Crie pasta de teste:
```bash
mkdir test-videos
```

Adicione v√≠deos de exerc√≠cios (MP4 ou WebM):
- `agachamento-lateral.mp4` - Vista sagital de agachamento
- `deadlift-lateral.mp4` - Vista sagital de terra
- `deadlift-posterior.mp4` - Vista posterior de terra

**Requisitos m√≠nimos dos v√≠deos:**
- Formato: MP4, WebM, AVI, MOV ou MKV
- Resolu√ß√£o m√≠nima: 640x480
- FPS m√≠nimo: 15
- Dura√ß√£o m√≠nima: 1 segundo
- Pessoa vis√≠vel de corpo inteiro

### Op√ß√£o 2: Gravar V√≠deos com Webcam

```bash
# Windows (usando FFmpeg)
ffmpeg -f dshow -i video="NomeWebcam" -t 10 -r 30 test-videos/teste.mp4

# macOS
ffmpeg -f avfoundation -i "0" -t 10 -r 30 test-videos/teste.mp4

# Linux
ffmpeg -f v4l2 -i /dev/video0 -t 10 -r 30 test-videos/teste.mp4
```

---

## üß™ Testes Graduais

### Teste 1: Verificar Estrutura de Arquivos

```bash
# Verificar que todos os arquivos foram criados
ls src/adapters/mediapipe.adapter.ts
ls src/services/pose-detection.service.ts
ls src/services/video-extraction.service.ts
ls src/services/movement-scoring.service.ts
ls src/pipelines/video-processing.pipeline.ts
ls src/pipelines/realtime-processing.pipeline.ts
ls src/utils/video.helpers.ts
ls src/examples/video-analysis.example.ts
```

**Resultado esperado:** Todos os arquivos existem ‚úÖ

---

### Teste 2: Compilar TypeScript

```bash
# Compilar todos os arquivos
npx tsc --noEmit --esModuleInterop --skipLibCheck src/**/*.ts
```

**Resultado esperado:**
- Se depend√™ncias instaladas: 0 erros ‚úÖ
- Se depend√™ncias N√ÉO instaladas: Apenas erros de m√≥dulos n√£o encontrados (OK)

---

### Teste 3: Testar Detector MediaPipe

Criar arquivo `test-detector.ts`:

```typescript
import { poseDetectionService } from './src/services/pose-detection.service';

async function test() {
  console.log('ü§ñ Inicializando detector MediaPipe...');

  try {
    await poseDetectionService.initialize();
    console.log('‚úÖ Detector inicializado com sucesso!');

    const info = poseDetectionService.getInfo();
    console.log('‚ÑπÔ∏è  Informa√ß√µes do detector:');
    console.log(`   Modelo: ${info.modelType}`);
    console.log(`   Backend: ${info.backend}`);

    console.log('\nüèÉ Executando benchmark...');
    const stats = await poseDetectionService.benchmark(5);
    console.log(`‚úÖ Benchmark conclu√≠do!`);
    console.log(`   Tempo m√©dio: ${stats.avgTime}ms`);
    console.log(`   FPS: ${stats.fps}`);

    await poseDetectionService.dispose();
    console.log('‚úÖ Detector descartado');
  } catch (error) {
    console.error('‚ùå Erro:', error);
  }
}

test();
```

**Executar:**
```bash
npx ts-node test-detector.ts
```

**Resultado esperado:**
```
ü§ñ Inicializando detector MediaPipe...
‚úÖ Detector inicializado com sucesso!
‚ÑπÔ∏è  Informa√ß√µes do detector:
   Modelo: SINGLEPOSE_THUNDER
   Backend: tensorflow
üèÉ Executando benchmark...
Progresso: 5/5
‚úÖ Benchmark conclu√≠do!
   Tempo m√©dio: 45.2ms
   FPS: 22.1
‚úÖ Detector descartado
```

---

### Teste 4: Testar Extra√ß√£o de V√≠deo

Criar arquivo `test-extraction.ts`:

```typescript
import { videoExtractionService } from './src/services/video-extraction.service';
import { getVideoInfo } from './src/utils/video.helpers';

async function test() {
  const videoPath = './test-videos/agachamento-lateral.mp4';

  console.log('üìπ Testando extra√ß√£o de v√≠deo...\n');

  try {
    // Obter informa√ß√µes
    const info = await getVideoInfo(videoPath);
    console.log('‚ÑπÔ∏è  Informa√ß√µes do v√≠deo:');
    console.log(`   Nome: ${info.name}`);
    console.log(`   Tamanho: ${info.size}`);
    console.log(`   Dura√ß√£o: ${info.duration}`);
    console.log(`   Resolu√ß√£o: ${info.resolution}`);
    console.log(`   FPS: ${info.fps}`);
    console.log(`   Qualidade: ${info.quality}`);

    // Extrair frames
    console.log('\nüìä Extraindo frames...');
    const frames = await videoExtractionService.extractFrames(videoPath, {
      outputDir: './temp-frames',
      fps: 15,
      maxFrames: 30,
      format: 'jpg',
      onProgress: (p) => process.stdout.write(`\r‚è≥ Progresso: ${p.toFixed(1)}%`)
    });

    console.log(`\n‚úÖ ${frames.length} frames extra√≠dos!`);

    // Cleanup
    await videoExtractionService.cleanupFrames('./temp-frames');
    console.log('‚úÖ Cleanup conclu√≠do');

  } catch (error) {
    console.error('‚ùå Erro:', error);
  }
}

test();
```

**Executar:**
```bash
npx ts-node test-extraction.ts
```

**Resultado esperado:**
```
üìπ Testando extra√ß√£o de v√≠deo...

‚ÑπÔ∏è  Informa√ß√µes do v√≠deo:
   Nome: agachamento-lateral.mp4
   Tamanho: 2.3MB
   Dura√ß√£o: 00:10
   Resolu√ß√£o: 1920x1080
   FPS: 30
   Qualidade: excelente

üìä Extraindo frames...
‚è≥ Progresso: 100.0%
‚úÖ 30 frames extra√≠dos!
‚úÖ Cleanup conclu√≠do
```

---

### Teste 5: Testar Pipeline Completo (ESSENCIAL)

Criar arquivo `test-pipeline.ts`:

```typescript
import { videoProcessingPipeline } from './src/pipelines/video-processing.pipeline';
import { CaptureMode, CameraAngle } from './src/types/biomechanical-analysis.types';

async function test() {
  const videoPath = './test-videos/agachamento-lateral.mp4';

  console.log('üé¨ Testando pipeline completo...\n');

  try {
    const result = await videoProcessingPipeline.process({
      videoPath,
      exerciseName: 'Agachamento Livre',
      captureMode: CaptureMode.ESSENTIAL,
      cameraAngle: CameraAngle.SAGITTAL_RIGHT,
      fps: 15,
      maxFrames: 45, // 3 segundos @ 15fps
      onProgress: (p) => process.stdout.write(`\r‚è≥ Progresso: ${p.toFixed(1)}%`)
    });

    console.log('\n\n‚úÖ Processamento conclu√≠do!\n');

    console.log('üìä Metadados:');
    console.log(`   Frames processados: ${result.metadata.processedFrames}/${result.metadata.totalFrames}`);
    console.log(`   Taxa de sucesso: ${result.metadata.successRate}%`);
    console.log(`   Tempo: ${(result.metadata.processingTimeMs / 1000).toFixed(1)}s`);
    console.log(`   FPS m√©dio: ${result.metadata.fps.toFixed(1)}`);

    console.log('\nüî¨ An√°lise Biomec√¢nica:');
    console.log(`   Confiabilidade: ${result.analysis.confidenceScore.toFixed(1)}% (${result.analysis.confidenceLevel})`);
    console.log(`   Risco: ${result.analysis.riskLevel}`);

    console.log('\nüìà Scores:');
    console.log(`   Motor: ${result.analysis.scores.motor.toFixed(1)}`);
    console.log(`   Stabilizer: ${result.analysis.scores.stabilizer.toFixed(1)}`);
    console.log(`   Symmetry: ${result.analysis.scores.symmetry.toFixed(1)}`);
    console.log(`   Compensation: ${result.analysis.scores.compensation.toFixed(1)}`);
    console.log(`   IGPB: ${result.analysis.scores.igpb.toFixed(1)}`);

    if (result.analysis.rotationAnalysis.detected) {
      console.log('\nüîÑ Rota√ß√£o Detectada:');
      console.log(`   Confian√ßa: ${result.analysis.rotationAnalysis.confidence}`);
      console.log(`   Tipo: ${result.analysis.rotationAnalysis.type}`);
      console.log(`   Magnitude: ${result.analysis.rotationAnalysis.magnitude.toFixed(1)}¬∞`);
    }

    console.log(`\nüí™ A√ß√µes Corretivas: ${result.analysis.correctiveActions.length}`);

  } catch (error) {
    console.error('‚ùå Erro:', error);
  }
}

test();
```

**Executar:**
```bash
npx ts-node test-pipeline.ts
```

**Resultado esperado:**
```
üé¨ Testando pipeline completo...

‚è≥ Progresso: 100.0%

‚úÖ Processamento conclu√≠do!

üìä Metadados:
   Frames processados: 42/45
   Taxa de sucesso: 93.3%
   Tempo: 15.2s
   FPS m√©dio: 2.8

üî¨ An√°lise Biomec√¢nica:
   Confiabilidade: 72.5% (alta)
   Risco: MODERATE

üìà Scores:
   Motor: 78.5
   Stabilizer: 72.3
   Symmetry: 85.0
   Compensation: 18.2
   IGPB: 76.8

üí™ A√ß√µes Corretivas: 2
```

---

### Teste 6: Executar Exemplos Completos

```bash
npx ts-node src/examples/video-analysis.example.ts
```

**Resultado esperado:**
- Executa 4 exemplos em sequ√™ncia
- Exibe an√°lises formatadas
- Retorna sem erros

---

## ‚úÖ Checklist de Valida√ß√£o

Marque cada item ap√≥s teste bem-sucedido:

- [ ] FFmpeg instalado e no PATH
- [ ] Depend√™ncias Node.js instaladas
- [ ] Compila√ß√£o TypeScript sem erros (exceto m√≥dulos n√£o encontrados)
- [ ] Detector MediaPipe inicializa corretamente
- [ ] Benchmark retorna FPS > 1
- [ ] Extra√ß√£o de v√≠deo funciona (frames criados)
- [ ] Pipeline completo processa v√≠deo
- [ ] Scores s√£o calculados (todos 0-100)
- [ ] An√°lise biomec√¢nica completa gerada
- [ ] Exemplos executam sem erro fatal

---

## üêõ Troubleshooting Comum

### Problema: "FFmpeg not found"

**Solu√ß√£o:**
```bash
# Verificar PATH
echo %PATH%  # Windows
echo $PATH   # Linux/Mac

# Adicionar FFmpeg ao PATH (Windows)
setx PATH "%PATH%;C:\ffmpeg\bin"

# Reiniciar terminal
```

### Problema: "Cannot find module @tensorflow/tfjs-node"

**Solu√ß√£o:**
```bash
npm cache clean --force
npm install @tensorflow/tfjs-node@^4.15.0 --save
```

### Problema: "Canvas build failed"

**Solu√ß√£o Windows:**
```bash
npm install --global --production windows-build-tools
npm install canvas --build-from-source
```

### Problema: "No pose detected"

**Causas:**
- Ilumina√ß√£o ruim
- Pessoa muito longe/perto
- Corpo n√£o vis√≠vel completamente

**Solu√ß√µes:**
- Melhorar ilumina√ß√£o
- Ajustar dist√¢ncia (2-4 metros ideal)
- Reduzir minPoseScore para 0.2

### Problema: "Processing muito lento (< 1 FPS)"

**Solu√ß√µes:**
1. Reduzir FPS: `fps: 15`
2. Limitar frames: `maxFrames: 30`
3. Usar GPU: `npm install @tensorflow/tfjs-node-gpu`
4. Usar modelo mais r√°pido: `SINGLEPOSE_LIGHTNING`

---

## üìä Resultados Esperados

### Performance T√≠pica (CPU i7)

| Configura√ß√£o | FPS | Tempo (30 frames) |
|--------------|-----|-------------------|
| 15fps extraction | 2-4 | 7-15s |
| 30fps extraction | 3-5 | 6-10s |
| 60fps extraction | 2-3 | 10-15s |

### Qualidade Esperada

| M√©trica | Valor Esperado |
|---------|----------------|
| Taxa de sucesso | > 80% |
| Confiabilidade | 60-85% (ESSENTIAL) |
| IGPB | 50-90 (depende da execu√ß√£o) |
| Landmarks detectados | 12-17 por frame |

---

## üéì Pr√≥ximos Passos

Ap√≥s todos os testes passarem:

1. **Testar com v√≠deos reais** de agachamento, terra e supino
2. **Ajustar thresholds** se necess√°rio
3. **Otimizar performance** (GPU, FPS reduzido)
4. **Integrar com API** existente
5. **Criar interface web** para visualiza√ß√£o

---

## üìû Suporte

Se algum teste falhar:

1. Verificar logs de erro detalhados
2. Consultar `VIDEO_PIPELINE_README.md` se√ß√£o Troubleshooting
3. Verificar que todas as depend√™ncias est√£o instaladas
4. Testar com v√≠deo de exemplo simples primeiro

---

**√öltima Atualiza√ß√£o**: 2026-02-15
**Vers√£o**: 1.0.0
