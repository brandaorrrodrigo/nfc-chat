# ğŸ§  Deep Analysis + RAG System

Sistema completo de anÃ¡lise profunda usando **RAG (Retrieval Augmented Generation)** + **LLM** para gerar relatÃ³rios biomecÃ¢nicos cientÃ­ficos.

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Arquitetura](#arquitetura)
- [Componentes](#componentes)
- [Setup](#setup)
- [Uso](#uso)
- [Pipeline RAG](#pipeline-rag)
- [Documentos CientÃ­ficos](#documentos-cientÃ­ficos)
- [Performance](#performance)
- [Troubleshooting](#troubleshooting)

---

## ğŸ¯ VisÃ£o Geral

O sistema Deep Analysis Ã© a **Camada 2** do pipeline hÃ­brido, executada APENAS quando a anÃ¡lise rÃ¡pida detecta problemas crÃ­ticos. Combina:

1. **RAG (Retrieval Augmented Generation)**: Busca contexto cientÃ­fico relevante
2. **LLM (Ollama)**: Gera narrativa profissional baseada em evidÃªncias
3. **Vector Store (Qdrant)**: Armazena e busca documentos cientÃ­ficos
4. **Embeddings**: RepresentaÃ§Ã£o vetorial de textos para busca semÃ¢ntica

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DEEP ANALYSIS SERVICE                        â”‚
â”‚  (Orquestrador principal)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                       â”‚
       â†“                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RAG SERVICE  â”‚      â”‚ OLLAMA       â”‚
â”‚              â”‚      â”‚ SERVICE      â”‚
â”‚ - Search     â”‚      â”‚              â”‚
â”‚ - Consolidateâ”‚      â”‚ - Generate   â”‚
â”‚ - Filter     â”‚      â”‚ - Retry      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EMBEDDING SERVICE                  â”‚
â”‚   (com cache Redis)                  â”‚
â”‚                                      â”‚
â”‚   - Generate embeddings              â”‚
â”‚   - Batch processing                 â”‚
â”‚   - Cache L2 (24h)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   VECTOR STORE SERVICE (Qdrant)      â”‚
â”‚                                      â”‚
â”‚   - Similarity search                â”‚
â”‚   - Filtros (deviation, evidence)    â”‚
â”‚   - IndexaÃ§Ã£o                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DOCUMENT PROCESSOR SERVICE         â”‚
â”‚                                      â”‚
â”‚   - Chunk documents                  â”‚
â”‚   - Generate embeddings              â”‚
â”‚   - Index in Qdrant                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Componentes

### 1. Deep Analysis Service
**Arquivo**: `deep-analysis.service.ts`

- Orquestrador principal
- Identifica desvios crÃ­ticos
- Busca contexto via RAG
- Gera narrativa com LLM
- Retorna relatÃ³rio completo

**MÃ©todos principais**:
```typescript
async analyze(input: DeepAnalysisInputDto): Promise<DeepAnalysisOutputDto>
```

### 2. RAG Service
**Arquivo**: `rag/rag.service.ts`

- Busca contexto cientÃ­fico relevante
- ConstrÃ³i queries otimizadas
- Filtra por evidÃªncia cientÃ­fica
- Consolida resultados de mÃºltiplas buscas

**MÃ©todos principais**:
```typescript
async searchContext(params: RagSearchParamsDto): Promise<RagSearchResultDto>
async searchMultipleDeviations(...): Promise<IScientificContext>
```

### 3. Embedding Service
**Arquivo**: `rag/embedding.service.ts`

- Gera embeddings usando Ollama (nomic-embed-text)
- **Cache Redis**: TTL 24h
- Batch processing (10 por vez)
- NormalizaÃ§Ã£o de texto

**MÃ©todos principais**:
```typescript
async generateEmbedding(text: string): Promise<number[]>
async generateEmbeddings(texts: string[]): Promise<number[][]>
```

### 4. Vector Store Service
**Arquivo**: `rag/vector-store.service.ts`

- Interface com Qdrant
- Busca por similaridade (cosine)
- Filtros avanÃ§ados
- GestÃ£o de coleÃ§Ãµes

**MÃ©todos principais**:
```typescript
async search(params: IVectorSearchParams): Promise<IVectorSearchResult[]>
async upsert(collectionName: string, points: IQdrantPoint[]): Promise<void>
```

### 5. Document Processor Service
**Arquivo**: `rag/document-processor.service.ts`

- Processa documentos cientÃ­ficos
- Chunking com overlap (400 palavras)
- GeraÃ§Ã£o de embeddings
- IndexaÃ§Ã£o no Qdrant

**MÃ©todos principais**:
```typescript
async processAndIndexDocuments(documentsPath: string): Promise<void>
async processDocument(document: IScientificDocument): Promise<number>
```

### 6. Ollama Service
**Arquivo**: `ollama/ollama.service.ts`

- IntegraÃ§Ã£o com Ollama LLM
- Retry logic (3 tentativas)
- Exponential backoff
- GeraÃ§Ã£o de embeddings

**MÃ©todos principais**:
```typescript
async generate(request: OllamaGenerateRequestDto): Promise<OllamaGenerateResponseDto>
async generateEmbedding(text: string): Promise<number[]>
```

---

## ğŸš€ Setup

### PrÃ©-requisitos

1. **Qdrant** (Vector Database)
2. **Ollama** (LLM local)
3. **Redis** (Cache)

### 1. Instalar Qdrant

```bash
# Docker
docker run -p 6333:6333 qdrant/qdrant

# Ou baixar: https://qdrant.tech/documentation/quick-start/
```

### 2. Instalar Ollama

```bash
# Linux/Mac
curl https://ollama.ai/install.sh | sh

# Windows: https://ollama.ai/download

# Pull models necessÃ¡rios
ollama pull llama3.1:8b
ollama pull nomic-embed-text
```

### 3. Configurar VariÃ¡veis de Ambiente

```env
# .env
QDRANT_URL=http://localhost:6333
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama3.1:8b
OLLAMA_MAX_RETRIES=3

EMBEDDING_MODEL=nomic-embed-text
EMBEDDING_CACHE_ENABLED=true
EMBEDDING_CACHE_TTL=86400

REDIS_HOST=localhost
REDIS_PORT=6379
```

### 4. Instalar DependÃªncias

```bash
cd backend
npm install @qdrant/js-client-rest ioredis
```

### 5. Popular RAG com Documentos CientÃ­ficos

```bash
# Adicionar documentos JSON em: backend/scientific-papers/

# Executar script de populaÃ§Ã£o
npm run populate-rag

# Ou com caminho customizado
npm run populate-rag -- --path=./my-papers
```

---

## ğŸ“š Documentos CientÃ­ficos

### Formato JSON

```json
{
  "title": "Study Title",
  "authors": "Smith J, Doe A",
  "year": 2020,
  "journal": "Journal Name",
  "doi": "10.1234/example",
  "abstract": "Study abstract...",
  "keywords": ["keyword1", "keyword2"],
  "content": "Full text of the study...",
  "metadata": {
    "evidence_level": "rct",
    "deviation_types": ["knee_valgus", "butt_wink"],
    "exercise_categories": ["lower_body_compound"],
    "study_type": "randomized-controlled-trial",
    "sample_size": 100,
    "population": "Athletes"
  }
}
```

### NÃ­veis de EvidÃªncia (Ordem de Prioridade)

1. **meta-analysis** - Meta-anÃ¡lise
2. **systematic-review** - RevisÃ£o sistemÃ¡tica
3. **rct** - Randomized Controlled Trial
4. **cohort** - Estudo de coorte
5. **case-control** - Caso-controle
6. **case-series** - SÃ©rie de casos
7. **expert-opinion** - OpiniÃ£o de especialistas

### Tipos de Desvio Suportados

- `knee_valgus` - Valgo de joelho
- `butt_wink` - RetroversÃ£o pÃ©lvica
- `forward_lean` - InclinaÃ§Ã£o anterior excessiva
- `heel_rise` - ElevaÃ§Ã£o dos calcanhares
- `asymmetric_loading` - Carga assimÃ©trica
- `excessive_spinal_flexion` - FlexÃ£o espinhal excessiva
- `shoulder_impingement` - Impacto de ombro
- `hip_shift` - Desvio lateral do quadril

---

## ğŸ”„ Pipeline RAG

### Fluxo Completo

```
1. Quick Analysis detecta desvios crÃ­ticos
        â†“
2. Deep Analysis Service inicia
        â†“
3. Para cada desvio crÃ­tico:
   a. RAG Service constrÃ³i query otimizada
   b. Embedding Service gera embedding da query
      - Verifica cache Redis
      - Se miss: chama Ollama
   c. Vector Store busca documentos similares
      - Filtros: deviation_type, evidence_level, year
      - Top K chunks (3 por desvio)
   d. Extrai fontes cientÃ­ficas Ãºnicas
        â†“
4. Consolida resultados de mÃºltiplas buscas
        â†“
5. ConstrÃ³i prompt com contexto cientÃ­fico
        â†“
6. Ollama LLM gera narrativa profissional
   - Retry logic (3x)
   - Exponential backoff
        â†“
7. Retorna relatÃ³rio completo
```

### Busca Vetorial

**Similaridade**: Cosine distance

**Filtros aplicados**:
- `deviation_type`: Tipo de desvio
- `exercise_category`: Categoria do exercÃ­cio
- `evidence_level`: RCT, systematic-review, meta-analysis
- `year`: >= 2010

**Score threshold**: 0.5 (relevÃ¢ncia mÃ­nima)

---

## âš¡ Performance

### Tempos Esperados

| Componente | Tempo | Notas |
|------------|-------|-------|
| Embedding generation | ~200ms | Por texto (cache miss) |
| Vector search | ~50ms | Qdrant local |
| LLM generation | ~10-30s | Depende do hardware |
| **Total Deep Analysis** | ~35s | 2 desvios, 6 chunks |

### OtimizaÃ§Ãµes

1. **Cache de Embeddings (Redis)**
   - Hit rate esperado: ~70%
   - TTL: 24 horas
   - Reduz tempo em ~200ms por busca

2. **Batch Processing**
   - Processa 10 embeddings por vez
   - Reduz overhead de chamadas HTTP

3. **Ãndices Qdrant**
   - Ãndices em: deviation_type, exercise_category, evidence_level
   - Busca ~10x mais rÃ¡pida

4. **Retry com Backoff**
   - Ollama pode falhar temporariamente
   - 3 tentativas com 2^n * 1000ms delay

---

## ğŸ§ª Testing

```bash
# Testes unitÃ¡rios
npm test deep-analysis.service.spec

# Testes de integraÃ§Ã£o
npm test -- --testPathPattern=deep-analysis.integration

# Coverage
npm run test:cov
```

---

## ğŸ› Troubleshooting

### Erro: "Qdrant connection refused"

**Causa**: Qdrant nÃ£o estÃ¡ rodando

**SoluÃ§Ã£o**:
```bash
docker run -d -p 6333:6333 qdrant/qdrant
```

### Erro: "Ollama generate timeout"

**Causa**: LLM estÃ¡ lento ou modelo nÃ£o estÃ¡ carregado

**SoluÃ§Ãµes**:
```bash
# Verificar se Ollama estÃ¡ rodando
ollama list

# Pull modelo se necessÃ¡rio
ollama pull llama3.1:8b

# Aumentar timeout (backend/.env)
OLLAMA_TIMEOUT=180000  # 3 minutos
```

### Erro: "No scientific context found"

**Causa**: RAG nÃ£o tem documentos indexados

**SoluÃ§Ã£o**:
```bash
# Popular RAG
npm run populate-rag

# Verificar quantos chunks
curl http://localhost:6333/collections/biomechanics_knowledge
```

### Performance Lenta

**Causas**:
1. Modelo Ollama muito pesado
2. Cache Redis desabilitado
3. Hardware limitado

**SoluÃ§Ãµes**:
```bash
# 1. Usar modelo mais leve
ollama pull llama3.1:7b

# 2. Habilitar cache
EMBEDDING_CACHE_ENABLED=true

# 3. Reduzir topK
topK: 2  # Menos chunks por desvio
```

---

## ğŸ“Š Monitoramento

### MÃ©tricas Importantes

1. **RAG Performance**
   - Average relevance score
   - Cache hit rate
   - Documents retrieved per query

2. **LLM Performance**
   - Generation time
   - Retry rate
   - Token usage

3. **System Health**
   - Qdrant status
   - Ollama availability
   - Redis connection

### Logs

```typescript
// Deep Analysis logs
logger.log('Starting deep analysis...');
logger.log('RAG retrieved X chunks from Y sources');
logger.log('Deep analysis completed in Xms');

// RAG logs
logger.debug('RAG query: "..."');
logger.log('RAG found X chunks from Y sources');

// Ollama logs
logger.debug('Ollama generate attempt X/Y');
logger.log('Ollama generation completed in Xms');
```

---

## ğŸ¯ Uso no CÃ³digo

### Exemplo BÃ¡sico

```typescript
import { DeepAnalysisService } from './deep-analysis.service';

// No worker ou controller
const deepAnalysis = await deepAnalysisService.analyze({
  quickAnalysis: quickResult,
  exerciseId: 'back-squat',
  userId: 'user_123',
  estimatedTime: 35000,
});

if (deepAnalysis) {
  console.log('Narrative:', deepAnalysis.llm_narrative);
  console.log('Sources:', deepAnalysis.rag_sources_used.length);
  console.log('Processing time:', deepAnalysis.processing_time_ms);
}
```

### IntegraÃ§Ã£o com Worker

```typescript
// Stage 5: Deep Analysis (CONDITIONAL)
if (decision.shouldRun) {
  await job.progress(60);

  const deepResult = await this.deepAnalysis.analyze({
    quickAnalysis: quickResult,
    exerciseId: job.data.exerciseId,
    userId: job.data.userId,
    estimatedTime: 35000,
  });

  // Salvar no banco
  await this.prisma.deepAnalysisResult.create({
    data: {
      video_analysis_id: videoAnalysis.id,
      rag_sources_used: deepResult.rag_sources_used,
      llm_narrative: deepResult.llm_narrative,
      scientific_context: deepResult.scientific_context,
      processing_time_ms: deepResult.processing_time_ms,
    },
  });
}
```

---

## ğŸ“ Checklist de Setup

- [ ] Qdrant instalado e rodando (port 6333)
- [ ] Ollama instalado e rodando (port 11434)
- [ ] Modelos Ollama baixados (llama3.1:8b, nomic-embed-text)
- [ ] Redis rodando (port 6379)
- [ ] VariÃ¡veis de ambiente configuradas
- [ ] DependÃªncias NPM instaladas
- [ ] Documentos cientÃ­ficos em `scientific-papers/`
- [ ] Script `populate-rag` executado
- [ ] Testes passando

---

## ğŸ‰ Status

âœ… **Sistema completo e funcional!**

- 6 serviÃ§os criados
- RAG com Qdrant + Ollama
- Cache Redis para embeddings
- Retry logic robusto
- Testes unitÃ¡rios
- Script de populaÃ§Ã£o
- DocumentaÃ§Ã£o completa

**PrÃ³ximos passos**: Integrar com worker BullMQ no Stage 5!
